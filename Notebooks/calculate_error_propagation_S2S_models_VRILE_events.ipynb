{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>calculate_error_propagation_S2S_models_VRILE_days_EVENTS_with_LOO.ipynb</code>.  We calculate the error propagation that occurs during/after VRILE days by analyzing forecasts that start a certain number of days before a VRILE event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from S2S_sea_ice_preprocess import load_model,create_aggregate_regions,create_model_climatology,create_obs_climatology\n",
    "from S2S_sea_ice_VRILEs import get_VRILE_days_EVENTS\n",
    "from S2S_sea_ice_metrics import calculate_errors,get_pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>inputs:</b><br>\n",
    "<li>  model name (ecmwf,ukmo,ncep,metreofr) </li>\n",
    "<li>  seas_str [string for season; ALL if we want to do full year]</li>\n",
    "<li>  seas_sel [months of season; empty if we want to do full year] </li>\n",
    "<li>  vrile_thresh [threshhold at which VRILE is estimated </li>\n",
    "<li>  thresh_str [string for VRILE threshhold] </li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'metreofr'\n",
    "seas_str = 'JJA'\n",
    "seas_sel = [6,7,8]\n",
    "obs_name = 'NSIDC_0079'\n",
    "WEEKLY = True\n",
    "lead_weeks = True\n",
    "vrile_thresh = 0.05\n",
    "thresh_str = '05'\n",
    "nday_change = 5 #number of days for VRILE calculation\n",
    "normalize = False\n",
    "VRILE_shift = 21 # days; number of days BEFORE VRILE to analyze\n",
    "COMMON_RF = True\n",
    "max_date_offset = 5 # days; number of days +/- the start of the VRILE\n",
    "drop_last = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model output for our desired model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files from  /home/disk/sipn/nicway/data/model/metreofr/reforecast/sipn_nc_agg_commonland/\n",
      "<xarray.Dataset>\n",
      "Dimensions:       (ensemble: 9, fore_time: 47, init_time: 834, nregions: 15)\n",
      "Coordinates:\n",
      "    region_names  (nregions) object dask.array<chunksize=(15,), meta=np.ndarray>\n",
      "  * ensemble      (ensemble) int32 0 1 2 3 4 5 6 7 8\n",
      "  * fore_time     (fore_time) timedelta64[ns] 0 days 1 days ... 45 days 46 days\n",
      "  * nregions      (nregions) int64 99 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      "  * init_time     (init_time) datetime64[ns] 1999-01-07 ... 2014-12-25\n",
      "Data variables:\n",
      "    Extent        (ensemble, init_time, fore_time, nregions) float64 dask.array<chunksize=(9, 1, 47, 15), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "SIE = load_model(model_name)\n",
    "print('loaded ',model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create aggregate regions that combine some of the NSIDC-MASIE regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE = create_aggregate_regions(SIE)\n",
    "print('combined regions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take ensemble mean, get lead time in days, and convert to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_ens_mean = SIE.mean(dim='ensemble')\n",
    "regions = SIE.region_names\n",
    "lead_days = SIE.fore_time.dt.days\n",
    "SIE_df = SIE_ens_mean.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the date for forecasts by adding the <code>fore_time</code> to <code>init_time</code>. Rename some columns to make life easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_df['valid date'] = SIE_df['init_time'] + SIE_df['fore_time']\n",
    "SIE_df = SIE_df.rename(columns={'region_names':'region',\n",
    "                           'fore_time':'lead time (days)',\n",
    "                           'init_time':'init date',\n",
    "                           'Extent':'SIE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create climatology for model output.  Decide how long we want weeks to be for weekly climatology (default is 7 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_length = 7\n",
    "SIE_df = create_model_climatology(SIE_df,7)\n",
    "print('model climatology created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load observations.  NSIDC_0079 is NASA Bootstrap, NSIDC_0051 is NASA team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'NSIDC_0051':\n",
    "    obs_type = 'sipn_nc_yearly_agg'\n",
    "else:\n",
    "    obs_type = 'sipn_nc_yearly_agg_commonland'\n",
    "filepath = '/home/disk/sipn/nicway/data/obs/{model_name}/{model_type}/'.format(model_name=obs_name,\n",
    "                                                                              model_type=obs_type)\n",
    "obs_filenames = xr.open_mfdataset(filepath+'/*.nc',combine='by_coords')\n",
    "print('opening ',obs_filenames)\n",
    "obs_SIE = obs_filenames.Extent\n",
    "obs_regions = obs_filenames.nregions\n",
    "obs_region_names = obs_filenames['region_names'].values\n",
    "# Drop region names and re-add as a non-dask.array object.  This is stupid but oh well\n",
    "obs_SIE = obs_SIE.drop('region_names')\n",
    "obs_SIE[\"region_names\"] = (\"nregions\",obs_region_names)\n",
    "print('obs loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add aggregate regions to obs and convert obs to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_SIE = create_aggregate_regions(obs_SIE)\n",
    "obs_SIE = obs_SIE.to_dataframe().reset_index()\n",
    "obs_SIE = obs_SIE.rename(columns={'Extent':'SIE','region_names':'region','time':'valid date'})\n",
    "obs_SIE['valid year'] = pd.to_datetime(obs_SIE['valid date']).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate our observed climatology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMON_RF == True:\n",
    "    obs_SIE = obs_SIE[pd.to_datetime(obs_SIE['valid date']).dt.year.isin(np.arange(1999,2015))]\n",
    "    obs_SIE = create_obs_climatology(obs_SIE)\n",
    "    time_str = 'COMMON_RF'\n",
    "    print('common reforecast')\n",
    "else:\n",
    "    time_str = 'FULL_PERIOD'\n",
    "    obs_SIE = create_obs_climatology(obs_SIE)\n",
    "    print('full period')\n",
    "print('observed climatology created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate RMSE based on VRILE events--we want to identify forecasts that start some number of days BEFORE the first day of a VRILE, and watch how the RMSE evolves.  So first, we need to get VRILE days and then identify forecasts that start $n$ days before.  We also need to track VRILE EVENTS--that is, if consecutive days are VRILE days, they are part of the same EVENT.  EVENTS must be separated by <code>BUFFER_DAYS</code> days to be considered separate events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings;\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_errors_ALL = pd.DataFrame()\n",
    "SIE_anom_errors_ALL = pd.DataFrame()\n",
    "SIE_errors_NO_ALL = pd.DataFrame()\n",
    "SIE_anom_errors_NO_ALL = pd.DataFrame()\n",
    "#\n",
    "SIE_VRILES_TEST = pd.DataFrame()\n",
    "obs_VRILES_TEST = pd.DataFrame()\n",
    "SIE_no_VRILES_TEST = pd.DataFrame()\n",
    "obs_no_VRILES_TEST = pd.DataFrame()\n",
    "SIE_anom_VRILES_TEST = pd.DataFrame()\n",
    "obs_anom_VRILES_TEST = pd.DataFrame()\n",
    "SIE_anom_no_VRILES_TEST = pd.DataFrame()\n",
    "obs_anom_no_VRILES_TEST = pd.DataFrame()\n",
    "#\n",
    "SIE_reg = SIE_df.set_index(['region'])\n",
    "regions_list = SIE_df['region'].unique().tolist()\n",
    "#\n",
    "pvalues_SIE = pd.DataFrame()\n",
    "pvalues_SIE_anom = pd.DataFrame()\n",
    "buffer_days = 14\n",
    "yrs = obs_SIE['valid year'].unique().tolist()\n",
    "#\n",
    "week_length = 7\n",
    "if (model_name != 'ukmo') & (drop_last == True):\n",
    "    max_fore = SIE_reg['lead time (days)'].max()\n",
    "    SIE_reg = SIE_reg.where(SIE_reg['lead time (days)'] < max_fore).dropna(how='all')\n",
    "#SIE_reg.groupby(['region','lead time (days)'])['SIE'].mean().xs('East Siberian-Beaufort-Chukchi Sea')#.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iyr in yrs:\n",
    "    obs_SIE_sel = obs_SIE[~obs_SIE['valid year'].isin([iyr])]\n",
    "    print('leaving out ',iyr)\n",
    "    # Estimate observed VRILE days\n",
    "    obs_SIE_VRILE_onlyx, obs_SIE_anom_VRILE_onlyx, obs_SIE_NO_VRILEx, obs_SIE_anom_NO_VRILEx = get_VRILE_days_EVENTS(obs_SIE_sel,vrile_thresh,nday_change,seas_sel,buffer_days)\n",
    "    print('VRILE days calculated')\n",
    "    #\n",
    "    # Now, we want to know how well the models forecast ONLY those VRILE days. \n",
    "    obs_SIE_VRILE_only = obs_SIE_VRILE_onlyx.set_index(['region'])\n",
    "    obs_SIE_anom_VRILE_only = obs_SIE_anom_VRILE_onlyx.set_index(['region'])\n",
    "    #\n",
    "    obs_SIE_NO_VRILE = obs_SIE_NO_VRILEx.set_index(['region'])\n",
    "    obs_SIE_anom_NO_VRILE = obs_SIE_anom_NO_VRILEx.set_index(['region'])\n",
    "    # Day we START our predictions is determined by VRILE_shift\n",
    "    obs_SIE_VRILE_only['valid date START'] = obs_SIE_VRILE_only['valid date'] - pd.Timedelta(VRILE_shift,'D')\n",
    "    obs_SIE_anom_VRILE_only['valid date START'] = obs_SIE_anom_VRILE_only['valid date'] - pd.Timedelta(VRILE_shift,'D')\n",
    "    # Now, we find model forecasts that start up to max_date_offset days before valid date START\n",
    "    SIE_df['lead time (weeks)'] = np.floor(SIE_df['lead time (days)'].dt.days/week_length)\n",
    "    SIE_df_reg = SIE_df.set_index(['region'])\n",
    "    #x_reg = 'panArctic'\n",
    "    region_list = obs_SIE_sel['region'].unique().tolist()\n",
    "    SIE_VRILES = pd.DataFrame()\n",
    "    obs_VRILES = pd.DataFrame()\n",
    "    SIE_no_VRILES = pd.DataFrame()\n",
    "    obs_no_VRILES = pd.DataFrame()\n",
    "    # Same, but for VRILES based on anomalous SIE\n",
    "    SIE_anom_VRILES = pd.DataFrame()\n",
    "    obs_anom_VRILES = pd.DataFrame()\n",
    "    SIE_anom_no_VRILES = pd.DataFrame()\n",
    "    obs_anom_no_VRILES = pd.DataFrame()\n",
    "    for x_reg in region_list:\n",
    "        #SIE_df_x = SIE_df.set_index(['region']).xs((x_reg))\n",
    "        dates_shifted = pd.DataFrame()\n",
    "        dates_shifted['region'] = x_reg\n",
    "        dates_shifted = pd.DataFrame(obs_SIE_VRILE_only.xs(x_reg)['valid date START'])\n",
    "        dates_shifted_list = pd.DataFrame(obs_SIE_VRILE_only.xs(x_reg)['valid date START'])\n",
    "        # Anom dates shifted\n",
    "        anom_dates_shifted = pd.DataFrame()\n",
    "        anom_dates_shifted['region'] = x_reg\n",
    "        anom_dates_shifted = pd.DataFrame(obs_SIE_anom_VRILE_only.xs(x_reg)['valid date START'])\n",
    "        anom_dates_shifted_list = pd.DataFrame(obs_SIE_anom_VRILE_only.xs(x_reg)['valid date START'])\n",
    "        #\n",
    "        for i in np.arange(1,max_date_offset+1):\n",
    "            #i_forward = dates_shifted + pd.Timedelta(i,'D')\n",
    "            i_backward = dates_shifted - pd.Timedelta(i,'D')\n",
    "            dates_shifted_list = dates_shifted_list.append((i_backward))\n",
    "            # same but for anom\n",
    "            #i_anom_forward = anom_dates_shifted + pd.Timedelta(i,'D')\n",
    "            i_anom_backward = anom_dates_shifted - pd.Timedelta(i,'D')\n",
    "            anom_dates_shifted_list = anom_dates_shifted_list.append((i_anom_backward)) \n",
    "        #dates_shifted_list_ALL = dates_shifted_list_ALL.append(dates_shifted_list)\n",
    "        x_SIE = SIE_df_reg.loc[x_reg]\n",
    "        x_SIE_VRILES = x_SIE[x_SIE['init date'].isin(dates_shifted_list['valid date START'])]\n",
    "        x_obs = obs_SIE_sel.set_index('region').loc[x_reg]\n",
    "        x_SIE_obs = x_obs[x_obs['valid date'].isin(x_SIE_VRILES['valid date'])]\n",
    "        SIE_VRILES = SIE_VRILES.append(x_SIE_VRILES)\n",
    "        obs_VRILES = obs_VRILES.append(x_SIE_obs)\n",
    "        #\n",
    "        x_SIE_no = x_SIE[~x_SIE['init date'].isin(dates_shifted_list['valid date START'])]\n",
    "        SIE_no_VRILES = SIE_no_VRILES.append(x_SIE_no)\n",
    "        x_no_obs = x_obs[x_obs['valid date'].isin(x_SIE_no['valid date'])]\n",
    "        obs_no_VRILES = obs_no_VRILES.append(x_no_obs)\n",
    "        ### Same, but for anom\n",
    "        x_anom_SIE_VRILES = x_SIE[x_SIE['init date'].isin(anom_dates_shifted_list['valid date START'])]\n",
    "        #x_anom_obs = obs_SIE.set_index('region').loc[x_reg]\n",
    "        x_anom_SIE_obs = x_obs[x_obs['valid date'].isin(x_anom_SIE_VRILES['valid date'])]\n",
    "        SIE_anom_VRILES = SIE_anom_VRILES.append(x_anom_SIE_VRILES)\n",
    "        obs_anom_VRILES = obs_anom_VRILES.append(x_anom_SIE_obs)\n",
    "        #\n",
    "        x_anom_SIE_no = x_SIE[~x_SIE['init date'].isin(anom_dates_shifted_list['valid date START'])]\n",
    "        SIE_anom_no_VRILES = SIE_anom_no_VRILES.append(x_anom_SIE_no)\n",
    "        x_anom_no_obs = x_obs[x_obs['valid date'].isin(x_anom_SIE_no['valid date'])]\n",
    "        obs_anom_no_VRILES = obs_anom_no_VRILES.append(x_anom_no_obs)\n",
    "        # Calculate RMSE and MAE\n",
    "        if x_reg == 'East Siberian-Beaufort-Chukchi Sea':\n",
    "            SIE_VRILES_TEST = SIE_VRILES_TEST.append(x_SIE_VRILES)\n",
    "            obs_VRILES_TEST = obs_VRILES_TEST.append(x_SIE_obs)\n",
    "            SIE_no_VRILES_TEST = SIE_no_VRILES_TEST.append(x_SIE_no)\n",
    "            obs_no_VRILES_TEST = obs_no_VRILES_TEST.append(x_no_obs)\n",
    "            SIE_anom_VRILES_TEST = SIE_anom_VRILES_TEST.append(x_anom_SIE_VRILES)\n",
    "            obs_anom_VRILES_TEST = obs_anom_VRILES_TEST.append(x_anom_SIE_obs)\n",
    "            SIE_anom_no_VRILES_TEST = SIE_anom_no_VRILES_TEST.append(x_anom_SIE_no)\n",
    "            obs_anom_no_VRILES_TEST = obs_anom_no_VRILES_TEST.append(x_anom_no_obs)\n",
    "    if lead_weeks == True:\n",
    "        clim_freq_str = 'WEEKLY'\n",
    "        SIE_VRILES['lead days'] = SIE_VRILES['lead time (weeks)']\n",
    "        SIE_anom_VRILES['lead days'] = SIE_anom_VRILES['lead time (weeks)']\n",
    "        SIE_raw_err,SIE_errors = calculate_errors(SIE_VRILES.reset_index(),obs_VRILES.reset_index())\n",
    "        SIE_anom_raw_err,SIE_anom_errors = calculate_errors(SIE_anom_VRILES.reset_index(),obs_anom_VRILES.reset_index())\n",
    "        ## NO VRILES\n",
    "        SIE_no_VRILES['lead days'] = SIE_no_VRILES['lead time (weeks)']\n",
    "        SIE_anom_no_VRILES['lead days'] = SIE_anom_no_VRILES['lead time (weeks)']\n",
    "        SIE_raw_err_NO,SIE_errors_NO = calculate_errors(SIE_no_VRILES.reset_index(),obs_SIE_sel)\n",
    "        SIE_anom_raw_err_NO,SIE_anom_errors_NO = calculate_errors(SIE_anom_no_VRILES.reset_index(),\n",
    "                                                                  obs_anom_no_VRILES.reset_index())\n",
    "    else:\n",
    "        clim_freq_str = 'DAILY'\n",
    "        SIE_VRILES['lead days'] = SIE_VRILES['lead time (days)'].dt.days\n",
    "        SIE_anom_VRILES['lead days'] = SIE_anom_VRILES['lead time (days)'].dt.days\n",
    "        SIE_raw_err,SIE_errors = calculate_errors(SIE_VRILES,obs_shifted_dates)\n",
    "        SIE_anom_raw_err,SIE_anom_errors = calculate_errors(SIE_anom_VRILES,obs_anom_shifted_dates)\n",
    "        ## NO VRILES\n",
    "        SIE_no_VRILES['lead days'] = SIE_no_VRILES['lead time (days)'].dt.days\n",
    "        SIE_anom_no_VRILES['lead days'] = SIE_anom_no_VRILES['lead time (days)'].dt.days\n",
    "        SIE_raw_err_NO,SIE_errors_NO = calculate_errors(SIE_no_VRILES,obs_no_shifted_dates)\n",
    "        SIE_anom_raw_err_NO,SIE_anom_errors_NO = calculate_errors(SIE_anom_no_VRILES,obs_anom_no_shifted_dates)\n",
    "    print('errors calculated')\n",
    "    #\n",
    "    # Get p-values\n",
    "    sd_VRILE,sd_noVRILE,p_value,N_vrile,N_novrile = get_pvalues(SIE_VRILES,SIE_no_VRILES,SIE_errors,SIE_errors_NO)\n",
    "    sd_VRILE_anom,sd_noVRILE_anom,p_value_anom,N_vrile_anom,N_novrile_anom = get_pvalues(SIE_anom_VRILES,\n",
    "                                                            SIE_anom_no_VRILES,SIE_anom_errors,SIE_anom_errors_NO)\n",
    "    # \n",
    "    # Add information to dataframes\n",
    "    SIE_errors['year out'] = iyr\n",
    "    SIE_errors['SIE sdev'] = sd_VRILE\n",
    "    SIE_errors['sample size'] = N_vrile\n",
    "    SIE_errors['p-value'] = p_value\n",
    "    SIE_errors_NO['year out'] = iyr\n",
    "    SIE_errors_NO['SIE sdev'] = sd_noVRILE\n",
    "    SIE_errors_NO['sample size'] = N_novrile\n",
    "    SIE_errors_NO['p-value'] = p_value\n",
    "    #\n",
    "    SIE_anom_errors['year out'] = iyr\n",
    "    SIE_anom_errors['SIE sdev'] = sd_VRILE_anom\n",
    "    SIE_anom_errors['sample size'] = N_vrile_anom\n",
    "    SIE_anom_errors['p-value'] = p_value_anom\n",
    "    SIE_anom_errors_NO['year out'] = iyr\n",
    "    SIE_anom_errors_NO['SIE sdev'] = sd_noVRILE_anom\n",
    "    SIE_anom_errors_NO['sample size'] = N_novrile_anom\n",
    "    SIE_anom_errors_NO['p-value'] = p_value_anom\n",
    "    # Append each CV slice to full data set\n",
    "    SIE_errors_ALL = SIE_errors_ALL.append(SIE_errors)\n",
    "    SIE_anom_errors_ALL = SIE_anom_errors_ALL.append(SIE_anom_errors)\n",
    "    SIE_errors_NO_ALL = SIE_errors_NO_ALL.append(SIE_errors_NO)\n",
    "    SIE_anom_errors_NO_ALL = SIE_anom_errors_NO_ALL.append(SIE_anom_errors_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SIE_anom_errors_ALL.where(SIE_anom_errors_ALL['region']=='East Siberian-Beaufort-Chukchi Sea').dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot RMSE vs lead time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(1)\n",
    "reg_sel = 'East Siberian-Beaufort-Chukchi Sea'\n",
    "ax1 = fig1.add_axes([0,0,1,1])\n",
    "foo = SIE_anom_errors_ALL.xs(reg_sel).reset_index()\n",
    "foo.plot.scatter(x='lead days',y=['SIE RMSE'],linewidth=2,linestyle='--',ax=ax1,color='r',label=['VRILES'])\n",
    "foo2 = SIE_anom_errors_NO_ALL.xs(reg_sel).reset_index()\n",
    "foo2.plot.scatter(x='lead days',y=['SIE RMSE'],linewidth=2,linestyle=':',ax=ax1,label=['NO VRILES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(2)\n",
    "ax2 = fig2.add_axes([0,0,1,1])\n",
    "foo = SIE_anom_errors_ALL.xs(reg_sel).reset_index()\n",
    "foo.plot.scatter(x='lead days',y=['SIE anom RMSE'],linewidth=2,linestyle='--',ax=ax2,color='r',label=['VRILES'])\n",
    "foo2 = SIE_anom_errors_NO_ALL.xs(reg_sel).reset_index()\n",
    "foo2.plot.scatter(x='lead days',y=['SIE anom RMSE'],linewidth=2,linestyle=':',ax=ax2,label=['NO VRILES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig4,(ax4a,ax4b) = plt.subplots(1,2,figsize=(15,6))\n",
    "foo = SIE_errors_ALL.xs(reg_sel).reset_index()\n",
    "sp4a = sns.scatterplot(data=foo,x='lead days',y='p-value',hue='year out',ax=ax4a,palette='tab20',legend=False)\n",
    "ax4a.axhline(-1.96,color='k')\n",
    "ax4a.axhline(1.96,color='k')\n",
    "SIE_errors_ALL_masked = SIE_errors_ALL.mask(SIE_errors_ALL['p-value'].abs()<1.96)\n",
    "foo2 = SIE_errors_ALL_masked.xs(reg_sel).reset_index()\n",
    "sns.scatterplot(data=foo2,x='lead days',y='p-value',hue='year out',s=200,legend=False,alpha=0.25,ax=ax4a,palette='tab20')\n",
    "sp4a.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax4a.set_title('SIE Forecasts')\n",
    "#\n",
    "sp4b = sns.scatterplot(data=SIE_anom_errors_ALL.xs(reg_sel).reset_index(),x='lead days',\n",
    "                       y='p-value',hue='year out',ax=ax4b,palette='tab20')\n",
    "ax4b.axhline(-1.96,color='k')\n",
    "ax4b.axhline(1.96,color='k')\n",
    "SIE_anom_errors_ALL_masked = SIE_anom_errors_ALL.mask(SIE_anom_errors_ALL['p-value'].abs()<1.96)\n",
    "sns.scatterplot(data=SIE_anom_errors_ALL_masked.xs(reg_sel).reset_index(),x='lead days',y='p-value',\n",
    "                hue='year out',s=200,legend=False,alpha=0.25,ax=ax4b,palette='tab20')\n",
    "sp4b.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax4b.set_title('Anomalous SIE Forecasts')\n",
    "ax4b.set_xlabel('lead weeks')\n",
    "ax4a.set_xlabel('lead weeks')\n",
    "#\n",
    "fig4.suptitle('p-values, VRILE days vs non-VRILE days, {reg_sel}, {model_name}, {seas_str}'.format(reg_sel=reg_sel,\n",
    "                                                            model_name=model_name,seas_str=seas_str),fontsize=20)\n",
    "#fpath_save_fig4 = figpath_save+'pvalues_each_fold_{reg_sel}_{model_name}_{seas_str}.png'.format(reg_sel=reg_sel,\n",
    "#                                                                    model_name=model_name,seas_str=seas_str)\n",
    "#fig4.savefig(fpath_save_fig4,format='png',dpi=350,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine everything together into one data frame. Replace <code>SIE anom RMSE</code> and <code>SIE anom MAE</code> in <code>SIE_errors</code> with corresponding entries from  <code>SIE_anom_errors</code> (and same for raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_errors_ALL['type'] = 'VRILE days'\n",
    "SIE_anom_errors_ALL['type'] = 'VRILE days'\n",
    "SIE_errors_ALL = SIE_errors_ALL.reset_index()\n",
    "SIE_anom_errors_ALL = SIE_anom_errors_ALL.reset_index()\n",
    "SIE_errors_ALL[['SIE anom RMSE','SIE anom MAE']] = SIE_anom_errors_ALL[['SIE anom RMSE','SIE anom MAE']]\n",
    "#SIE_errors_ALL['type'] = 'VRILE days'\n",
    "#\n",
    "SIE_errors_NO_ALL['type'] = 'no VRILE days'\n",
    "SIE_anom_errors_NO_ALL['type'] = 'no VRILE days'\n",
    "SIE_errors_NO_ALL = SIE_errors_NO_ALL.reset_index()\n",
    "SIE_anom_errors_NO_ALL = SIE_anom_errors_NO_ALL.reset_index()\n",
    "SIE_errors_NO_ALL[['SIE anom RMSE','SIE anom MAE']] = SIE_anom_errors_NO_ALL[['SIE anom RMSE','SIE anom MAE']]\n",
    "#\n",
    "SIE_errors_FULL = SIE_errors_ALL.append(SIE_errors_NO_ALL)\n",
    "# Same for raw errors\n",
    "SIE_raw_err = SIE_raw_err.reset_index()\n",
    "SIE_anom_raw_err = SIE_anom_raw_err.reset_index()\n",
    "SIE_raw_err[['SIE anom']] = SIE_anom_raw_err['SIE anom']\n",
    "SIE_raw_err['type'] = 'VRILE days'\n",
    "#\n",
    "SIE_raw_err_NO = SIE_raw_err_NO.reset_index()\n",
    "SIE_anom_raw_err_NO = SIE_anom_raw_err_NO.reset_index()\n",
    "SIE_raw_err_NO[['SIE anom']] = SIE_anom_raw_err_NO['SIE anom']\n",
    "SIE_raw_err_NO['type'] = 'no VRILE days'\n",
    "#\n",
    "SIE_raw_err_FULL = SIE_raw_err.append(SIE_raw_err_NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '/home/disk/sipn/mcmcgraw/McGraw_etal_2020/code/make_it_nice/COMMON_LAND_MASK/data/{model_name}/'.format(model_name=model_name)\n",
    "fdir = fdir+'OBS_{obs_name}/'.format(obs_name=obs_name)\n",
    "if COMMON_RF == True:\n",
    "    fdir = fdir+'COMMON_RF/'\n",
    "else:\n",
    "    fdir = fdir+'FULL_TIME/'\n",
    "if nday_change != 5:\n",
    "    fdir = fdir+'VRILEs_{nday_change}day_change/'.format(nday_change=nday_change)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "#\n",
    "\n",
    "fname_save_RMSE = fdir+'ERROR_PROP_{VRILE_shift}day_shift_VRILE_vs_NOVRILE_RMSE_MAE_{model_name}_months{seas_str}_VRILE{thresh_str}_model_clim_freq_{clim_freq_str}.csv'.format(VRILE_shift=VRILE_shift,\n",
    "model_name=model_name,seas_str=seas_str,thresh_str=thresh_str,clim_freq_str=clim_freq_str)\n",
    "#\n",
    "#SIE_raw_err_FULL.to_csv(fname_save_raw)\n",
    "SIE_errors_FULL.to_csv(fname_save_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fname_save_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sea_ice_variability_S2S",
   "language": "python",
   "name": "sea_ice_variability_s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
